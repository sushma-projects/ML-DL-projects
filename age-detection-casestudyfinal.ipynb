{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Detection of Indian Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is taken from below link:\n",
    "\n",
    "https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facial feature analysis has always been a topic of interest mainly due to its applicability. Deep Learning techniques are now making it possible for face analysis to be not just a dream but a reality. This practice problem is get you more acquainted with deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian Movie Face DataBase(IMFDB) is a large unconstrained face database consisting of 34512 images of 100 Indian actors collected from more than 100 videos. All the images are manually selected and cropped from the video frames resulting in a high degree of variability interms of scale, pose, expression, illumination, age, resolution, occlusion and makeup. IMFDB is the first face database that provides a detailed annotation of every image in terms of age, pose, gender, expression and type of occlusion that may help other face related applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is cleaned and formatted to give you a total of 26742 images with 19906 images in train and 6636 images in test.\n",
    "\n",
    "The attributes of data are as follows:\n",
    "\n",
    "ID-Unique ID of image\n",
    "\n",
    "Class-Age bin of person in image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "The task is to predict the age of a person from his or her facial attributes. For simplicity, the problem has been converted to a multiclass problem with classes as Young, Middle and Old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loding Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Importing\n",
    "%pylab inline\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "#from keras.preprocessing import image\n",
    "#from keras.preprocessing import load_img,img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD,Adam,Adamax\n",
    "from keras.layers import Input\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense,Dropout,Flatten, Conv2D,MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19906, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6636, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17814.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21283.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16496.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4487.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   Class\n",
       "0    377.jpg  MIDDLE\n",
       "1  17814.jpg   YOUNG\n",
       "2  21283.jpg  MIDDLE\n",
       "3  16496.jpg   YOUNG\n",
       "4   4487.jpg  MIDDLE"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25321.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>989.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19277.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13093.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5367.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID\n",
       "0  25321.jpg\n",
       "1    989.jpg\n",
       "2  19277.jpg\n",
       "3  13093.jpg\n",
       "4   5367.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIDDLE</th>\n",
       "      <td>10804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLD</th>\n",
       "      <td>2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOUNG</th>\n",
       "      <td>6706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID\n",
       "Class        \n",
       "MIDDLE  10804\n",
       "OLD      2396\n",
       "YOUNG    6706"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by = \"Class\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: YOUNG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d60892f28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Random image and its lable from train data set\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "i = random.choice(train.index)\n",
    "img_name = train.ID[i]\n",
    "img = imread(os.path.join('Train', img_name))\n",
    "print(\"Age:\" , train.Class[i])\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing images data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizing images of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Loading the Images\n",
    "from scipy.misc import imresize\n",
    "train_images=[]\n",
    "for img_name in train.ID:\n",
    "    trainpath = os.path.join('Train',img_name)\n",
    "    image = imread(trainpath)\n",
    "    image = imresize(image, (64,64))\n",
    "    image = image.astype('float32')\n",
    "    train_images.append(image)\n",
    "    \n",
    "train_x = np.stack(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "test_images=[]\n",
    "for img_name in test.ID:\n",
    "    testpath = os.path.join('Test',img_name)\n",
    "    image = imread(testpath)\n",
    "    image = imresize(image, (64,64))\n",
    "    image = image.astype('float32')\n",
    "    test_images.append(image)\n",
    "    \n",
    "test_x = np.stack(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6636"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing pixels\n",
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Label encoder\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Converting target variable to categorical variable\n",
    "label = LabelEncoder()\n",
    "train_y = label.fit_transform(train.Class)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19906, 64, 64, 3), (6636, 64, 64, 3), (19906, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,test_x.shape,train_y.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15924, 64, 64, 3), (3982, 64, 64, 3), (15924, 3), (3982, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "            featurewise_center=True,\n",
    "            featurewise_std_normalization=True,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAug = ImageDataGenerator(\n",
    "            featurewise_center=True,\n",
    "            featurewise_std_normalization=True,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAug.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15924, 64, 64, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 64, 64, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAug.fit(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6636, 64, 64, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Models using convolution neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Architecture of Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the sequential model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 176,355\n",
      "Trainable params: 176,355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ravikiran\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "19906/19906 [==============================] - 488s 25ms/step - loss: 0.5158 - acc: 0.7467\n",
      "Epoch 2/40\n",
      "19906/19906 [==============================] - 500s 25ms/step - loss: 0.4629 - acc: 0.7854\n",
      "Epoch 3/40\n",
      "19906/19906 [==============================] - 577s 29ms/step - loss: 0.4334 - acc: 0.8017\n",
      "Epoch 4/40\n",
      "19906/19906 [==============================] - 472s 24ms/step - loss: 0.4156 - acc: 0.8135\n",
      "Epoch 5/40\n",
      "19906/19906 [==============================] - 495s 25ms/step - loss: 0.4013 - acc: 0.8204\n",
      "Epoch 6/40\n",
      "19906/19906 [==============================] - 496s 25ms/step - loss: 0.3876 - acc: 0.8282\n",
      "Epoch 7/40\n",
      "19906/19906 [==============================] - 459s 23ms/step - loss: 0.3802 - acc: 0.8342\n",
      "Epoch 8/40\n",
      "19906/19906 [==============================] - 481s 24ms/step - loss: 0.3717 - acc: 0.8383\n",
      "Epoch 9/40\n",
      "19906/19906 [==============================] - 455s 23ms/step - loss: 0.3659 - acc: 0.8413\n",
      "Epoch 10/40\n",
      "19906/19906 [==============================] - 484s 24ms/step - loss: 0.3575 - acc: 0.8468\n",
      "Epoch 11/40\n",
      "19906/19906 [==============================] - 462s 23ms/step - loss: 0.3574 - acc: 0.8457\n",
      "Epoch 12/40\n",
      "19906/19906 [==============================] - 475s 24ms/step - loss: 0.3547 - acc: 0.8485\n",
      "Epoch 13/40\n",
      "19906/19906 [==============================] - 482s 24ms/step - loss: 0.3570 - acc: 0.8474\n",
      "Epoch 14/40\n",
      "19906/19906 [==============================] - 459s 23ms/step - loss: 0.3545 - acc: 0.8494\n",
      "Epoch 15/40\n",
      "19906/19906 [==============================] - 460s 23ms/step - loss: 0.3531 - acc: 0.8494\n",
      "Epoch 16/40\n",
      "19906/19906 [==============================] - 469s 24ms/step - loss: 0.3489 - acc: 0.8517\n",
      "Epoch 17/40\n",
      "19906/19906 [==============================] - 504s 25ms/step - loss: 0.3499 - acc: 0.8536\n",
      "Epoch 18/40\n",
      "19906/19906 [==============================] - 461s 23ms/step - loss: 0.3499 - acc: 0.8543\n",
      "Epoch 19/40\n",
      "19906/19906 [==============================] - 510s 26ms/step - loss: 0.3476 - acc: 0.8535\n",
      "Epoch 20/40\n",
      "19906/19906 [==============================] - 495s 25ms/step - loss: 0.3506 - acc: 0.8529\n",
      "Epoch 21/40\n",
      "19906/19906 [==============================] - 481s 24ms/step - loss: 0.3443 - acc: 0.8546\n",
      "Epoch 22/40\n",
      "19906/19906 [==============================] - 490s 25ms/step - loss: 0.3458 - acc: 0.8562\n",
      "Epoch 23/40\n",
      "19906/19906 [==============================] - 485s 24ms/step - loss: 0.3469 - acc: 0.8566\n",
      "Epoch 24/40\n",
      "19906/19906 [==============================] - 471s 24ms/step - loss: 0.3442 - acc: 0.8559\n",
      "Epoch 25/40\n",
      "19906/19906 [==============================] - 486s 24ms/step - loss: 0.3477 - acc: 0.8559\n",
      "Epoch 26/40\n",
      "19906/19906 [==============================] - 475s 24ms/step - loss: 0.3525 - acc: 0.8559\n",
      "Epoch 27/40\n",
      "19906/19906 [==============================] - 470s 24ms/step - loss: 0.3439 - acc: 0.8555\n",
      "Epoch 28/40\n",
      "19906/19906 [==============================] - 462s 23ms/step - loss: 0.3504 - acc: 0.8546\n",
      "Epoch 29/40\n",
      "19906/19906 [==============================] - 473s 24ms/step - loss: 0.3482 - acc: 0.8558\n",
      "Epoch 30/40\n",
      "19906/19906 [==============================] - 461s 23ms/step - loss: 0.3462 - acc: 0.8552\n",
      "Epoch 31/40\n",
      "19906/19906 [==============================] - 617s 31ms/step - loss: 0.3545 - acc: 0.8541\n",
      "Epoch 32/40\n",
      "19906/19906 [==============================] - 484s 24ms/step - loss: 0.3555 - acc: 0.8539\n",
      "Epoch 33/40\n",
      "19906/19906 [==============================] - 515s 26ms/step - loss: 0.3541 - acc: 0.8528\n",
      "Epoch 34/40\n",
      "19906/19906 [==============================] - 486s 24ms/step - loss: 0.3541 - acc: 0.8537\n",
      "Epoch 35/40\n",
      "19906/19906 [==============================] - 490s 25ms/step - loss: 0.3546 - acc: 0.8525\n",
      "Epoch 36/40\n",
      "19906/19906 [==============================] - 497s 25ms/step - loss: 0.3611 - acc: 0.8548\n",
      "Epoch 37/40\n",
      "19906/19906 [==============================] - 482s 24ms/step - loss: 0.3576 - acc: 0.8512\n",
      "Epoch 38/40\n",
      "19906/19906 [==============================] - 473s 24ms/step - loss: 0.3609 - acc: 0.8500\n",
      "Epoch 39/40\n",
      "19906/19906 [==============================] - 463s 23ms/step - loss: 0.3615 - acc: 0.8488\n",
      "Epoch 40/40\n",
      "19906/19906 [==============================] - 479s 24ms/step - loss: 0.3585 - acc: 0.8512\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=32, epochs=40,verbose=1)\n",
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "pred = label.inverse_transform(pred)\n",
    "\n",
    "test['Class'] = pred\n",
    "test.to_csv('submission_age.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_vgg16.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "img_height,img_width = 64,64\n",
    "num_classes = 3\n",
    "#If imagenet weights are being loaded,input must have a static square shape\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(img_height,img_width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0926 12:43:37.903225 140149613623040 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model_resnet = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 16, 16, 64)   4160        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 16, 16, 256)  16640       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 16, 16, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 16, 16, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 256)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 16, 16, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 256)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 16, 16, 64)   16448       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 16, 16, 64)   36928       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 16, 16, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 16, 16, 256)  16640       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 16, 16, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 16, 16, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 256)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 512)    0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 512)    0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8, 8, 512)    0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 8, 512)    0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 4, 4, 1024)   0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 4, 4, 1024)   0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 4, 4, 1024)   0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, 4, 1024)   0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, 4, 1024)   0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 4, 1024)   0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 2, 2, 2048)   0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 2, 2, 2048)   0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 2, 2, 2048)   0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            6147        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "adam = Adam(lr=0.0001)\n",
    "model_resnet.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"model_resnet.h5\",monitor=\"val_loss\",mode=\"min\",save_best_only=True,verbose=1)\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\",mode=\"min\",min_delta=0,patience=10,verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\",factor=0.2,patience=1,verbose=1,min_delta=0.0001)\n",
    "#tensorboard = TensorBoard(log_dir=\"graph_1\",histogram_freq=0,batch_size=128,write_graph=True,write_grads=False,\n",
    "#                            write_images=False,embeddings_freq=0,embeddings_layer_names=None,embeddings_metadata=None,\n",
    "#                            embeddings_data=None,update_freq='epoch')\n",
    "callbacks = [checkpoint,earlystop,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0926 12:43:45.719814 140149613623040 deprecation.py:323] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/30\n",
      "15924/15924 [==============================] - 725s 46ms/step - loss: 1.8656 - acc: 0.4371 - val_loss: 1.5856 - val_acc: 0.5515\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.58556, saving model to model_resnet.h5\n",
      "Epoch 2/30\n",
      "15924/15924 [==============================] - 698s 44ms/step - loss: 1.4423 - acc: 0.4793 - val_loss: 1.4336 - val_acc: 0.5520\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.58556 to 1.43361, saving model to model_resnet.h5\n",
      "Epoch 3/30\n",
      "15924/15924 [==============================] - 698s 44ms/step - loss: 1.2791 - acc: 0.5008 - val_loss: 1.1826 - val_acc: 0.5472\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.43361 to 1.18256, saving model to model_resnet.h5\n",
      "Epoch 4/30\n",
      "15924/15924 [==============================] - 697s 44ms/step - loss: 1.1788 - acc: 0.5369 - val_loss: 1.2901 - val_acc: 0.5779\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.18256\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 5/30\n",
      "15924/15924 [==============================] - 699s 44ms/step - loss: 1.0643 - acc: 0.5650 - val_loss: 1.0050 - val_acc: 0.5763\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.18256 to 1.00501, saving model to model_resnet.h5\n",
      "Epoch 6/30\n",
      "15924/15924 [==============================] - 698s 44ms/step - loss: 1.0273 - acc: 0.5786 - val_loss: 0.9529 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00501 to 0.95286, saving model to model_resnet.h5\n",
      "Epoch 7/30\n",
      "15924/15924 [==============================] - 699s 44ms/step - loss: 0.9709 - acc: 0.6022 - val_loss: 1.0561 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.95286\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 8/30\n",
      "15924/15924 [==============================] - 699s 44ms/step - loss: 0.9572 - acc: 0.6114 - val_loss: 0.9939 - val_acc: 0.5881\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.95286\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Epoch 9/30\n",
      "15924/15924 [==============================] - 698s 44ms/step - loss: 0.9374 - acc: 0.6157 - val_loss: 0.9685 - val_acc: 0.5864\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.95286\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "Epoch 10/30\n",
      "15924/15924 [==============================] - 698s 44ms/step - loss: 0.9298 - acc: 0.6144 - val_loss: 0.9608 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.95286\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "Epoch 11/30\n",
      "15924/15924 [==============================] - 697s 44ms/step - loss: 0.9204 - acc: 0.6200 - val_loss: 0.9556 - val_acc: 0.5914\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.95286\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "Epoch 12/30\n",
      "15924/15924 [==============================] - 698s 44ms/step - loss: 0.9415 - acc: 0.6144 - val_loss: 0.9527 - val_acc: 0.5899\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.95286 to 0.95272, saving model to model_resnet.h5\n",
      "Epoch 13/30\n",
      "15924/15924 [==============================] - 698s 44ms/step - loss: 0.9395 - acc: 0.6139 - val_loss: 0.9491 - val_acc: 0.5897\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.95272 to 0.94913, saving model to model_resnet.h5\n",
      "Epoch 14/30\n",
      "15924/15924 [==============================] - 700s 44ms/step - loss: 0.9539 - acc: 0.6124 - val_loss: 0.9471 - val_acc: 0.5894\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.94913 to 0.94713, saving model to model_resnet.h5\n",
      "Epoch 15/30\n",
      "15924/15924 [==============================] - 699s 44ms/step - loss: 0.9284 - acc: 0.6192 - val_loss: 0.9465 - val_acc: 0.5884\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.94713 to 0.94648, saving model to model_resnet.h5\n",
      "Epoch 16/30\n",
      "15924/15924 [==============================] - 700s 44ms/step - loss: 0.9132 - acc: 0.6205 - val_loss: 0.9462 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.94648 to 0.94618, saving model to model_resnet.h5\n",
      "Epoch 17/30\n",
      "15924/15924 [==============================] - 702s 44ms/step - loss: 0.9435 - acc: 0.6126 - val_loss: 0.9474 - val_acc: 0.5892\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.94618\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "Epoch 18/30\n",
      "15924/15924 [==============================] - 703s 44ms/step - loss: 0.9264 - acc: 0.6250 - val_loss: 0.9459 - val_acc: 0.5897\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.94618 to 0.94588, saving model to model_resnet.h5\n",
      "Epoch 19/30\n",
      "15924/15924 [==============================] - 702s 44ms/step - loss: 0.9334 - acc: 0.6189 - val_loss: 0.9452 - val_acc: 0.5904\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.94588 to 0.94521, saving model to model_resnet.h5\n",
      "Epoch 20/30\n",
      "15924/15924 [==============================] - 714s 45ms/step - loss: 0.9239 - acc: 0.6171 - val_loss: 0.9448 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.94521 to 0.94483, saving model to model_resnet.h5\n",
      "Epoch 21/30\n",
      "15924/15924 [==============================] - 704s 44ms/step - loss: 0.9326 - acc: 0.6112 - val_loss: 0.9448 - val_acc: 0.5899\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.94483\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
      "Epoch 22/30\n",
      "15924/15924 [==============================] - 701s 44ms/step - loss: 0.9357 - acc: 0.6163 - val_loss: 0.9454 - val_acc: 0.5917\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.94483\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
      "Epoch 23/30\n",
      "15924/15924 [==============================] - 702s 44ms/step - loss: 0.9489 - acc: 0.6086 - val_loss: 0.9453 - val_acc: 0.5892\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.94483\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0239999126415712e-11.\n",
      "Epoch 24/30\n",
      "15924/15924 [==============================] - 702s 44ms/step - loss: 0.9331 - acc: 0.6191 - val_loss: 0.9435 - val_acc: 0.5892\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.94483 to 0.94350, saving model to model_resnet.h5\n",
      "Epoch 25/30\n",
      "15924/15924 [==============================] - 702s 44ms/step - loss: 0.9549 - acc: 0.6113 - val_loss: 0.9445 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.94350\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.0479997905886727e-12.\n",
      "Epoch 26/30\n",
      "15924/15924 [==============================] - 706s 44ms/step - loss: 0.9342 - acc: 0.6181 - val_loss: 0.9436 - val_acc: 0.5879\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.94350\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0959995811773456e-13.\n",
      "Epoch 27/30\n",
      "15924/15924 [==============================] - 716s 45ms/step - loss: 0.9305 - acc: 0.6126 - val_loss: 0.9437 - val_acc: 0.5899\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.94350\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 8.191999053934474e-14.\n",
      "Epoch 28/30\n",
      "15924/15924 [==============================] - 721s 45ms/step - loss: 0.9547 - acc: 0.6138 - val_loss: 0.9461 - val_acc: 0.5886\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.94350\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.638399837891949e-14.\n",
      "Epoch 29/30\n",
      "15924/15924 [==============================] - 723s 45ms/step - loss: 0.9442 - acc: 0.6146 - val_loss: 0.9472 - val_acc: 0.5886\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.94350\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.27679981130917e-15.\n",
      "Epoch 30/30\n",
      "15924/15924 [==============================] - 722s 45ms/step - loss: 0.9505 - acc: 0.6150 - val_loss: 0.9465 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.94350\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.553599792024929e-16.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7688d60be0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet.fit(X_train,y_train,epochs=30,batch_size=512,validation_data=(X_test,y_test),callbacks=callbacks)\n",
    "#model_resnet.save_weights('model_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3982 [==============================] - 26s 7ms/step\n",
      "Loss = 0.9465157491726112\n",
      "Test Accuracy = 0.5909090909240594\n"
     ]
    }
   ],
   "source": [
    "preds = model_resnet.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.load_weights(os.path.join(\"model_resnet.h5\"))\n",
    "pred = model_resnet.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6636, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict_classes(test_x)\n",
    "pred= np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Class'] = pred\n",
    "test.to_csv('submission_age_resnet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0927 08:51:32.478157 140247048369920 deprecation_wrapper.py:119] From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0927 08:51:32.779580 140247048369920 deprecation_wrapper.py:119] From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0927 08:51:32.913552 140247048369920 deprecation_wrapper.py:119] From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0927 08:51:33.113555 140247048369920 deprecation_wrapper.py:119] From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "img_height,img_width = 64,64\n",
    "num_classes = 3\n",
    "#If imagenet weights are being loaded,input must have a static square shape\n",
    "base_model = VGG16(weights=None, include_top=False, input_shape=(img_height,img_width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 08:51:44.187951 140247048369920 deprecation_wrapper.py:119] From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0927 08:51:44.196738 140247048369920 deprecation.py:506] From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0927 08:51:44.197654 140247048369920 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model_vgg16 = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 14,716,227\n",
      "Trainable params: 14,716,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 08:52:41.866947 140247048369920 deprecation_wrapper.py:119] From /home/jupyter/.local/lib/python3.5/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0927 08:52:41.874631 140247048369920 deprecation_wrapper.py:119] From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "adam = Adam(lr=0.0001)\n",
    "model_vgg16.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"model_vgg16.h5\",monitor=\"val_loss\",mode=\"min\",save_best_only=True,verbose=1)\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\",mode=\"min\",min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\",factor=0.2,patience=1,verbose=1,min_delta=0.0001)\n",
    "callbacks = [checkpoint,earlystop,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 08:52:58.929013 140247048369920 deprecation.py:323] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/20\n",
      "15924/15924 [==============================] - 771s 48ms/step - loss: 0.9835 - acc: 0.5261 - val_loss: 0.9499 - val_acc: 0.5477\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94994, saving model to model_vgg16.h5\n",
      "Epoch 2/20\n",
      "15924/15924 [==============================] - 773s 49ms/step - loss: 0.9547 - acc: 0.5409 - val_loss: 0.9407 - val_acc: 0.5477\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.94994 to 0.94066, saving model to model_vgg16.h5\n",
      "Epoch 3/20\n",
      "15924/15924 [==============================] - 759s 48ms/step - loss: 0.9464 - acc: 0.5402 - val_loss: 0.9524 - val_acc: 0.5477\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.94066\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 4/20\n",
      "15924/15924 [==============================] - 760s 48ms/step - loss: 0.9332 - acc: 0.5410 - val_loss: 0.9152 - val_acc: 0.5477\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.94066 to 0.91520, saving model to model_vgg16.h5\n",
      "Epoch 5/20\n",
      "15924/15924 [==============================] - 757s 48ms/step - loss: 0.9196 - acc: 0.5394 - val_loss: 0.9060 - val_acc: 0.5477\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.91520 to 0.90600, saving model to model_vgg16.h5\n",
      "Epoch 6/20\n",
      "15924/15924 [==============================] - 761s 48ms/step - loss: 0.8981 - acc: 0.5437 - val_loss: 0.9024 - val_acc: 0.5671\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.90600 to 0.90239, saving model to model_vgg16.h5\n",
      "Epoch 7/20\n",
      "15924/15924 [==============================] - 764s 48ms/step - loss: 0.8627 - acc: 0.5805 - val_loss: 0.8390 - val_acc: 0.6158\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.90239 to 0.83896, saving model to model_vgg16.h5\n",
      "Epoch 8/20\n",
      "15924/15924 [==============================] - 767s 48ms/step - loss: 0.8222 - acc: 0.6170 - val_loss: 0.7811 - val_acc: 0.6482\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.83896 to 0.78112, saving model to model_vgg16.h5\n",
      "Epoch 9/20\n",
      "15924/15924 [==============================] - 761s 48ms/step - loss: 0.7911 - acc: 0.6415 - val_loss: 0.8077 - val_acc: 0.6318\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.78112\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 10/20\n",
      "15924/15924 [==============================] - 773s 49ms/step - loss: 0.7785 - acc: 0.6424 - val_loss: 0.7577 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.78112 to 0.75771, saving model to model_vgg16.h5\n",
      "Epoch 11/20\n",
      "15924/15924 [==============================] - 772s 48ms/step - loss: 0.7689 - acc: 0.6512 - val_loss: 0.7544 - val_acc: 0.6647\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.75771 to 0.75438, saving model to model_vgg16.h5\n",
      "Epoch 12/20\n",
      "15924/15924 [==============================] - 758s 48ms/step - loss: 0.7665 - acc: 0.6523 - val_loss: 0.7578 - val_acc: 0.6647\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.75438\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Epoch 13/20\n",
      "15924/15924 [==============================] - 769s 48ms/step - loss: 0.7611 - acc: 0.6566 - val_loss: 0.7521 - val_acc: 0.6640\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.75438 to 0.75205, saving model to model_vgg16.h5\n",
      "Epoch 14/20\n",
      "15924/15924 [==============================] - 799s 50ms/step - loss: 0.7603 - acc: 0.6542 - val_loss: 0.7508 - val_acc: 0.6630\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.75205 to 0.75081, saving model to model_vgg16.h5\n",
      "Epoch 15/20\n",
      "15924/15924 [==============================] - 773s 49ms/step - loss: 0.7625 - acc: 0.6556 - val_loss: 0.7501 - val_acc: 0.6640\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.75081 to 0.75015, saving model to model_vgg16.h5\n",
      "Epoch 16/20\n",
      "15924/15924 [==============================] - 763s 48ms/step - loss: 0.7606 - acc: 0.6564 - val_loss: 0.7490 - val_acc: 0.6650\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.75015 to 0.74899, saving model to model_vgg16.h5\n",
      "Epoch 17/20\n",
      "15924/15924 [==============================] - 759s 48ms/step - loss: 0.7604 - acc: 0.6569 - val_loss: 0.7487 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.74899 to 0.74866, saving model to model_vgg16.h5\n",
      "Epoch 18/20\n",
      "15924/15924 [==============================] - 757s 48ms/step - loss: 0.7589 - acc: 0.6545 - val_loss: 0.7487 - val_acc: 0.6662\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.74866\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "Epoch 19/20\n",
      "15924/15924 [==============================] - 756s 47ms/step - loss: 0.7577 - acc: 0.6572 - val_loss: 0.7481 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.74866 to 0.74808, saving model to model_vgg16.h5\n",
      "Epoch 20/20\n",
      "15924/15924 [==============================] - 754s 47ms/step - loss: 0.7589 - acc: 0.6561 - val_loss: 0.7481 - val_acc: 0.6662\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.74808\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d608aa470>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16.fit(X_train,y_train,epochs=20,batch_size=512,validation_data=(X_test,y_test),callbacks=callbacks)\n",
    "#model.save_weights('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3982 [==============================] - 41s 10ms/step\n",
      "Loss = 0.7481389540873958\n",
      "Test Accuracy = 0.6662481165842337\n"
     ]
    }
   ],
   "source": [
    "preds = model_vgg16.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.load_weights(os.path.join(\"model_vgg16.h5\"))\n",
    "pred = model_vgg16.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict_classes(test_x)\n",
    "#pred = label.inverse_transform(pred)\n",
    "pred= np.argmax(pred,axis=1)\n",
    "test['Class'] = pred\n",
    "test.to_csv('submission_age_vgg16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------+------------+\n",
      "|        Model         | Accuracy | Train loss |\n",
      "+----------------------+----------+------------+\n",
      "|         CNN          |   0.85   |    0.35    |\n",
      "| Pre-trained ResNet50 |   0.61   |    0.94    |\n",
      "|  Pre-trained VGG16   |   0.65   |    0.75    |\n",
      "+----------------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "pretty_table = PrettyTable()\n",
    "pretty_table.field_names = [\"Model\", \"Accuracy\", \"Train loss\"]\n",
    "pretty_table.add_row([\"CNN\",\"0.85\",\"0.35\"])\n",
    "pretty_table.add_row([\"Pre-trained ResNet50\",\"0.61\",\"0.94\"])\n",
    "pretty_table.add_row([\"Pre-trained VGG16\",\"0.65\",\"0.75\"])\n",
    "\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "    As performance was not improved for all the models as it is shown for simple CNN model train accuracy and loss is \n",
    "    better so predicted class labels on test data,stored in csv file for submitting it into competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
